{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.model_vit import vit_base_patch16\n",
    "import rasterio\n",
    "from pyproj import Transformer\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and load a pretrained Copernicus-FM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-13 12:05:01--  https://huggingface.co/wangyi111/Copernicus-FM/resolve/main/CopernicusFM_ViT_base_varlang_e100.pth\n",
      "Resolving huggingface.co (huggingface.co)... 3.160.150.2, 3.160.150.119, 3.160.150.7, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.160.150.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.hf.co/repos/5d/56/5d5698bc57b0453934b47e33f6ad19062a8419378967ef8a9a20b5400e0d4db0/539c5dd95cdf5b95fac1c4540929eaeb24b53a694a3421535ef3322a51644397?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27CopernicusFM_ViT_base_varlang_e100.pth%3B+filename%3D%22CopernicusFM_ViT_base_varlang_e100.pth%22%3B&Expires=1741867502&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MTg2NzUwMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzVkLzU2LzVkNTY5OGJjNTdiMDQ1MzkzNGI0N2UzM2Y2YWQxOTA2MmE4NDE5Mzc4OTY3ZWY4YTlhMjBiNTQwMGUwZDRkYjAvNTM5YzVkZDk1Y2RmNWI5NWZhYzFjNDU0MDkyOWVhZWIyNGI1M2E2OTRhMzQyMTUzNWVmMzMyMmE1MTY0NDM5Nz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=sIKzKn8kmU0XK6VtNDfsu0ETD9z8RiSdU3XHAYp6aFWIs1Frz8wejIXA7ux2%7EEi9oxY9dk3TPsqE7pfjVnxaz7lSPZUlXS4j5Znf30A0tte4GIkuuJH34SHeKqZ2TWrvsgn01v6t8pZqyu-JhOQ0JU8DuMu1IJ-HNsDeZHvqN5AqMKe1Q5fuJErWs45IIB61GCbtN2InI7sDpEEgVfZOJcG27jEvJPKGU-xXZKyQ6QP4KA0l9tEZdLvQSE4RdCnxa53HvR5WGtJzY262Q9AgaHbU0pILJ2n%7EvRc-DQbm2mCDhWy4DhuoN3MCTf-mYAD1w1y3dRW-b4i3O63DfpTO5g__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
      "--2025-03-13 12:05:03--  https://cdn-lfs-us-1.hf.co/repos/5d/56/5d5698bc57b0453934b47e33f6ad19062a8419378967ef8a9a20b5400e0d4db0/539c5dd95cdf5b95fac1c4540929eaeb24b53a694a3421535ef3322a51644397?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27CopernicusFM_ViT_base_varlang_e100.pth%3B+filename%3D%22CopernicusFM_ViT_base_varlang_e100.pth%22%3B&Expires=1741867502&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MTg2NzUwMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzVkLzU2LzVkNTY5OGJjNTdiMDQ1MzkzNGI0N2UzM2Y2YWQxOTA2MmE4NDE5Mzc4OTY3ZWY4YTlhMjBiNTQwMGUwZDRkYjAvNTM5YzVkZDk1Y2RmNWI5NWZhYzFjNDU0MDkyOWVhZWIyNGI1M2E2OTRhMzQyMTUzNWVmMzMyMmE1MTY0NDM5Nz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=sIKzKn8kmU0XK6VtNDfsu0ETD9z8RiSdU3XHAYp6aFWIs1Frz8wejIXA7ux2%7EEi9oxY9dk3TPsqE7pfjVnxaz7lSPZUlXS4j5Znf30A0tte4GIkuuJH34SHeKqZ2TWrvsgn01v6t8pZqyu-JhOQ0JU8DuMu1IJ-HNsDeZHvqN5AqMKe1Q5fuJErWs45IIB61GCbtN2InI7sDpEEgVfZOJcG27jEvJPKGU-xXZKyQ6QP4KA0l9tEZdLvQSE4RdCnxa53HvR5WGtJzY262Q9AgaHbU0pILJ2n%7EvRc-DQbm2mCDhWy4DhuoN3MCTf-mYAD1w1y3dRW-b4i3O63DfpTO5g__&Key-Pair-Id=K24J24Z295AEI9\n",
      "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.173.205.60, 18.173.205.32, 18.173.205.47, ...\n",
      "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.173.205.60|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 557940490 (532M) [binary/octet-stream]\n",
      "Saving to: ‘CopernicusFM_ViT_base_varlang_e100.pth’\n",
      "\n",
      "CopernicusFM_ViT_ba 100%[===================>] 532.09M  46.6MB/s    in 11s     \n",
      "\n",
      "2025-03-13 12:05:14 (47.1 MB/s) - ‘CopernicusFM_ViT_base_varlang_e100.pth’ saved [557940490/557940490]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download weights\n",
    "!wget https://huggingface.co/wangyi111/Copernicus-FM/resolve/main/CopernicusFM_ViT_base_varlang_e100.pth -P ./weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=['mask_token'])\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = vit_base_patch16(num_classes=10, global_pool=False)\n",
    "\n",
    "# load pre-trained weights\n",
    "path = './weights/CopernicusFM_ViT_base_varlang_e100.pth'\n",
    "check_point = torch.load(path)\n",
    "if 'model' in check_point:\n",
    "    state_dict = check_point['model']\n",
    "else:\n",
    "    state_dict = check_point\n",
    "msg = model.load_state_dict(state_dict, strict=False)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode a image from any spectral or non-spectral sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral input: any stack of spectral bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding a spectral image with shape torch.Size([1, 4, 264, 264]), and expected patch size 16.\n",
      "torch.Size([1, 10]) torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# load an example Sentinel-2 image\n",
    "img_path = 'assets/20201002T221611_20201002T221610_T60HWB.tif'\n",
    "with rasterio.open(img_path) as src:\n",
    "    img = src.read((2,3,4,8)) # take R,G,B,NIR bands for example\n",
    "    img = img.astype(np.float32) / 10000.0 # normalize to [0,1], just for demonstration here, we recommend z-score normalization in practice\n",
    "    # get meta: geocoordinates\n",
    "    cx,cy = src.xy(src.height // 2, src.width // 2)\n",
    "    if src.crs.to_string() != 'EPSG:4326':\n",
    "        crs_transformer = Transformer.from_crs(src.crs, 'epsg:4326', always_xy=True)\n",
    "        lon, lat = crs_transformer.transform(cx,cy)\n",
    "    else:\n",
    "        lon, lat = cx, cy\n",
    "# get meta: time\n",
    "img_fname = os.path.basename(img_path)\n",
    "date_str = img_fname.split('_')[1][:8]\n",
    "date_obj = date(int(date_str[:4]), int(date_str[4:6]), int(date_str[6:8]))\n",
    "reference_date = date(1970, 1, 1)\n",
    "delta = (date_obj - reference_date).days\n",
    "# get meta: patch area\n",
    "patch_area = (16*10/1000)**2 # patchsize 16 pix, gsd 10m\n",
    "\n",
    "# metadata tensor\n",
    "meta = np.array([lon, lat, delta, patch_area]).astype(np.float32)\n",
    "meta = torch.from_numpy(meta)\n",
    "\n",
    "img = torch.from_numpy(img).unsqueeze(0) # add batch dimension, [1, C, H, W]\n",
    "meta = meta.unsqueeze(0) # add batch dimension, [1, 4]\n",
    "key = 'any' # not used\n",
    "wvs = [490, 560, 665, 842] # wavelength: B,G,R,NIR (Sentinel 2)\n",
    "bws = [65, 35, 30, 115] # bandwidth: B,G,R,NIR (Sentinel 2)\n",
    "language_embed = None # N/A\n",
    "kernel_size = 16 # expected patch size\n",
    "input_mode = 'spectral'\n",
    "\n",
    "print('Encoding a spectral image with shape {}, and expected patch size {}.'.format(img.shape, kernel_size))\n",
    "logit, embed = model(img, meta, key, wvs, bws, language_embed, input_mode, kernel_size)\n",
    "print(logit.shape, embed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-spectral input: any image with a variable name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding a predefined variable image with name \"s5p_no2\", shape torch.Size([1, 1, 56, 56]), and expected patch size 4.\n",
      "torch.Size([1, 10]) torch.Size([1, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/p/project/hai_ssl4eo/wang_yi/software/miniconda3/envs/dinov2/lib/python3.9/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "# example 1: pre-defined variable in Copernicus-FM (s5p_no2, s5p_co, s5p_o3, s5p_so2, dem)\n",
    "img = torch.randn(1, 1, 56, 56)\n",
    "meta = torch.full((1, 4), float('nan')) # [lon, lat, delta_time, patch_token_area], assume unknown\n",
    "key = 's5p_no2' # to index the predefined language embedding, if a new language embedding is input, key is not used\n",
    "wvs = [0] # not used\n",
    "bws = [0] # not used\n",
    "language_embed = None # s5p_no2 is predefined in the model\n",
    "kernel_size = 4 # expected patch size\n",
    "input_mode = 'variable'\n",
    "\n",
    "print('Encoding a predefined variable image with name \"{}\", shape {}, and expected patch size {}.'.format(key, img.shape, kernel_size))\n",
    "logit, embed = model(img, meta, key, wvs, bws, language_embed, input_mode, kernel_size)\n",
    "print(logit.shape, embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding a new variable image with name \"temperature\", shape torch.Size([1, 1, 112, 112]), and expected patch size 8.\n",
      "torch.Size([1, 10]) torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# example 2: new variable\n",
    "img = torch.randn(1, 1, 112, 112)\n",
    "meta = torch.full((1, 4), float('nan')) # meta unavailable\n",
    "key = 'temperature' # this is a new variable, key not used\n",
    "wvs = [0] # not used\n",
    "bws = [0] # not used\n",
    "language_embed = torch.randn(2048) # new language embedding, can be acquired from a pre-trained language model using the variable name\n",
    "kernel_size = 8 # expected patch size\n",
    "input_mode = 'variable'\n",
    "\n",
    "print('Encoding a new variable image with name \"{}\", shape {}, and expected patch size {}.'.format(key, img.shape, kernel_size))\n",
    "logit, embed = model(img, meta, key, wvs, bws, language_embed, input_mode, kernel_size)\n",
    "print(logit.shape, embed.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
